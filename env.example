#Data Base 접속 정보
NEO4J_URI=bolt://127.0.0.1:7687
NEO4J_INSTANCE=CSADB
NEO4J_DATABASE=csadb01
NEO4J_USER=csauser
NEO4J_PASSWORD=<your-password>
NEO4J_POOL_SIZE=10
NEO4J_BATCH_SIZE=25

JAVA_SOURCE_FOLDER = target_src/sml-fns-online
#DB_SCRIPT_FOLDER = target_src/car-center-devlab/src/main/resources/db/prod
USE_NEO4J_BEAN_RESOLVER=true
# 스트리밍 파싱 모드 활성화 (병렬처리 + 메모리 효율)
USE_STREAMING_PARSE=true

# Java 파싱 병렬 워커 수 (기본값: 자동 설정 - max(4, CPU 코어수-2))
# 설정하지 않으면 시스템의 CPU 코어 수에 따라 자동 설정됨
# 예: 8코어 시스템 → 6 워커, 16코어 시스템 → 14 워커, 4코어 시스템 → 4 워커
# 수동 설정이 필요한 경우에만 아래 주석을 해제하여 사용
#JAVA_PARSE_WORKERS=8

# Java 파일 파싱 타임아웃 (기본값: 60초)
# 단일 파일 파싱에 소요되는 최대 시간
# 복잡한 파일이 많으면 증가, 빠른 실패가 필요하면 감소
JAVA_FILE_PARSE_TIMEOUT=120.0

# Java 파일 복잡도 임계값 (기본값: 50000)
# 이 값을 초과하는 파일은 분석에서 제외됩니다
# 극단적으로 복잡한 파일(필드 수 500개 이상)을 건너뛰어 전체 분석 속도 향상
JAVA_COMPLEXITY_THRESHOLD=50000

# DTO 클래스 소스 코드 저장 건너뛰기 (기본값: false)
# DTO/VO/Entity 클래스의 소스 코드를 Neo4j에 저장하지 않음
# 파싱 시간 10-20%, DB 저장 시간 40-60%, 메모리 30-40% 절감 효과
# 단, DTO 클래스의 소스 코드 조회는 불가능해짐
SKIP_DTO_SOURCE=true

# DTO 클래스 메서드 분석 생략 (기본값: true)
# true: DTO 메서드 분석 생략 (성능 향상, 필드는 여전히 분석됨)
# false: 모든 메서드 분석 (클래스 명세서에 메서드 포함)
SKIP_DTO_METHODS=true

# LOG_LEVEL can be: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# 출력 디렉터리 설정 (선택사항)
SEQUENCE_DIAGRAM_OUTPUT_DIR=output/sequence-diagram
CRUD_MATRIX_OUTPUT_DIR=output/crud-matrix
CLASS_SPEC_OUTPUT_DIR=output/class-spec
IMPACT_ANALYSIS_OUTPUT_DIR=output/impact-analysis

# AI 분석 시스템 활성화 (기본값: false)
# true로 설정하면 AIAnalyzer가 초기화되어 AI 분석 기능 사용 가능
# false로 설정하면 AI 관련 기능 전체 비활성화
USE_AI_ANALYSIS=true

# AI Enrichment 동시 요청 수 (기본값: 10)
# ai-enrich 명령어에서 동시에 처리할 노드 수
# 로컬 LLM (LM Studio): 10-20 권장
# 클라우드 API (Google, OpenAI): 5-10 권장
# Rate Limit 발생 시 이 값을 줄여서 재시도
CONCURRENT_AI_REQUESTS=15

# AI Enrichment 배치 크기 (deprecated: 하위 호환성을 위해 유지)
# 대신 CONCURRENT_AI_REQUESTS 사용을 권장합니다
AI_ENRICHMENT_BATCH_SIZE=50

# AI Provider 설정 (google, groq, lmstudio, openai 중 선택)
AI_PROVIDER=lmstudio

# Google Gemini 설정
GOOGLE_API_KEY=<your-api-key>
GEMINI_MODEL_NAME=gemini-2.0-flash
GOOGLE_CENAI_USE_VERTEXAI=FALSE

# Groq 설정
GROQ_API_KEY=<your-api-key>
GROQ_MODEL_NAME=qwen/qwen3-32b

# LM Studio 설정
LMSTUDIO_BASE_URL=http://localhost:1234/v1
#LMSTUDIO_MODEL_NAME=qwen/qwen3-8b
#LMSTUDIO_MODEL_NAME=qwen2.5-coder-7b-instruct
#LMSTUDIO_MODEL_NAME=exaone-4.0-1.2b
LMSTUDIO_MODEL_NAME=a.x-4.0-light

# OpenAI 설정
OPENAI_API_KEY=ollama
OPENAI_MODEL_NAME=gpt-oss:20b
#OPENAI_MODEL_NAME=qwen3:30b
OPENAI_BASE_URL=http://devlab.skax.co.kr/ollama/v1