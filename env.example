#Data Base 접속 정보
NEO4J_URI=bolt://127.0.0.1:7687
NEO4J_INSTANCE=CSADB
NEO4J_DATABASE=csadb01
NEO4J_USER=csauser
NEO4J_PASSWORD=<your-password>
NEO4J_POOL_SIZE=10
NEO4J_BATCH_SIZE=25

JAVA_SOURCE_FOLDER = target_src/car-center-devlab
DB_SCRIPT_FOLDER = target_src/car-center-devlab/src/main/resources/db/prod
USE_NEO4J_BEAN_RESOLVER=true
# 스트리밍 파싱 모드 활성화 (병렬처리 + 메모리 효율)
USE_STREAMING_PARSE=true

# Java 파싱 병렬 워커 수 (기본값: 8)
# CPU 코어 수에 맞게 조정 (권장: 4-16)
JAVA_PARSE_WORKERS=8

# Java 파일 파싱 타임아웃 (기본값: 60초)
# 단일 파일 파싱에 소요되는 최대 시간
# 복잡한 파일이 많으면 증가, 빠른 실패가 필요하면 감소
JAVA_FILE_PARSE_TIMEOUT=60.0

# Java 파일 복잡도 임계값 (기본값: 50000)
# 이 값을 초과하는 파일은 분석에서 제외됩니다
# 극단적으로 복잡한 파일(필드 수 500개 이상)을 건너뛰어 전체 분석 속도 향상
JAVA_COMPLEXITY_THRESHOLD=50000

# DTO 클래스 최적화 (기본값: false)
# DTO/VO/Entity 클래스의 소스 코드 저장 및 필드 논리명 추출 건너뛰기
# 효과:
#   - 소스 저장: DB 저장 시간 40-60% 절감, 메모리 30-40% 절감
#   - 필드 논리명 추출: 파싱 시간 70-90% 절감 (100개 필드 = 200초 → 20초)
# 트레이드오프: DTO 클래스의 소스 코드 조회 및 필드 논리명 불가
SKIP_DTO_SOURCE=false

# LOG_LEVEL can be: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# 출력 디렉터리 설정 (선택사항)
SEQUENCE_DIAGRAM_OUTPUT_DIR=output/sequence-diagram
CRUD_MATRIX_OUTPUT_DIR=output/crud-matrix
CLASS_SPEC_OUTPUT_DIR=output/class-spec
IMPACT_ANALYSIS_OUTPUT_DIR=output/impact-analysis

#AI를 적용해서 Class, Method, SQL document 문장 생성(default = false)
AI_USE_ANALYSIS=true

# AI Enrichment 동시 요청 수 (기본값: 10)
# ai-enrich 명령어에서 동시에 처리할 노드 수
# 로컬 LLM (LM Studio): 10-20 권장
# 클라우드 API (Google, OpenAI): 5-10 권장
# Rate Limit 발생 시 이 값을 줄여서 재시도
CONCURRENT_AI_REQUESTS=15

# AI Enrichment 배치 크기 (deprecated: 하위 호환성을 위해 유지)
# 대신 CONCURRENT_AI_REQUESTS 사용을 권장합니다
AI_ENRICHMENT_BATCH_SIZE=50

# AI Provider 설정 (google, groq, lmstudio, openai 중 선택)
AI_PROVIDER=lmstudio

# Google Gemini 설정
GOOGLE_API_KEY=<your-api-key>
GEMINI_MODEL_NAME=gemini-2.0-flash
GOOGLE_CENAI_USE_VERTEXAI=FALSE

# Groq 설정
GROQ_API_KEY=<your-api-key>
GROQ_MODEL_NAME=qwen/qwen3-32b

# LM Studio 설정
LMSTUDIO_BASE_URL=http://localhost:1234/v1
#LMSTUDIO_MODEL_NAME=qwen/qwen3-8b
#LMSTUDIO_MODEL_NAME=qwen2.5-coder-7b-instruct
#LMSTUDIO_MODEL_NAME=exaone-4.0-1.2b
LMSTUDIO_MODEL_NAME=a.x-4.0-light

# OpenAI 설정
OPENAI_API_KEY=ollama
OPENAI_MODEL_NAME=gpt-oss:20b
#OPENAI_MODEL_NAME=qwen3:30b
OPENAI_BASE_URL=http://devlab.skax.co.kr/ollama/v1